{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: sentimental analysis model using word2vec gensim to calculate the cosine similarity between three  sentences\n",
        "\n",
        "!pip install gensim\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "sentences = [\n",
        "    \"This is a very good movie.\",\n",
        "    \"The movie is excellent.\",\n",
        "    \"The film is quite bad.\"\n",
        "]\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Lowercases and tokenizes the input text.\"\"\"\n",
        "    text = text.lower()\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "tokenized_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
        "\n",
        "# Train a Word2Vec model (or load a pre-trained one)\n",
        "model = Word2Vec(sentences=tokenized_sentences, min_count=1, vector_size=100, window=5)\n",
        "\n",
        "def sentence_embedding(sentence, model):\n",
        "  \"\"\"Creates an embedding for a sentence using word embeddings from a model.\"\"\"\n",
        "  tokens = preprocess_text(sentence)\n",
        "  vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "  if vectors:\n",
        "    return np.mean(vectors, axis=0).reshape(1,-1)  # Reshape for cosine_similarity\n",
        "  else:\n",
        "      return np.zeros((1, 100))  # Return zero vector if no words found in vocab\n",
        "\n",
        "\n",
        "sentence1_embedding = sentence_embedding(sentences[0], model)\n",
        "sentence2_embedding = sentence_embedding(sentences[1], model)\n",
        "sentence3_embedding = sentence_embedding(sentences[2], model)\n",
        "\n",
        "\n",
        "similarity1_2 = cosine_similarity(sentence1_embedding, sentence2_embedding)[0][0]\n",
        "similarity1_3 = cosine_similarity(sentence1_embedding, sentence3_embedding)[0][0]\n",
        "similarity2_3 = cosine_similarity(sentence2_embedding, sentence3_embedding)[0][0]\n",
        "\n",
        "print(f\"Cosine similarity between sentence 1 and 2: {similarity1_2}\")\n",
        "print(f\"Cosine similarity between sentence 1 and 3: {similarity1_3}\")\n",
        "print(f\"Cosine similarity between sentence 2 and 3: {similarity2_3}\")"
      ],
      "metadata": {
        "id": "kuZcO0VFnTny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}