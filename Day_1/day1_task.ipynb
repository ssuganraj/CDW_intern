{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" My name is Suganraj, am third year Computer Science Student and I'm passionate about artificial intelligence and machine learning and i have done certification in AWS cloud practitioner and Microsost Azure Ai 900 and done projects in Machine learning and cloud computing.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_text = [word for word in text.split() if word.lower() not in stop_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'Suganraj,', 'third', 'year', 'Computer', 'Science', 'Student', \"I'm\", 'passionate', 'artificial', 'intelligence', 'machine', 'learning', 'done', 'certification', 'AWS', 'cloud', 'practitioner', 'Microsost', 'Azure', 'Ai', '900', 'done', 'projects', 'Machine', 'learning', 'cloud', 'computing.']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    original_word stemmed_word\n",
      "0            name         name\n",
      "1       Suganraj,    suganraj,\n",
      "2           third        third\n",
      "3            year         year\n",
      "4        Computer       comput\n",
      "5         Science       scienc\n",
      "6         Student      student\n",
      "7             I'm          i'm\n",
      "8      passionate      passion\n",
      "9      artificial     artifici\n",
      "10   intelligence     intellig\n",
      "11        machine       machin\n",
      "12       learning        learn\n",
      "13           done         done\n",
      "14  certification       certif\n",
      "15            AWS           aw\n",
      "16          cloud        cloud\n",
      "17   practitioner   practition\n",
      "18      Microsost    microsost\n",
      "19          Azure         azur\n",
      "20             Ai           ai\n",
      "21            900          900\n",
      "22           done         done\n",
      "23       projects      project\n",
      "24        Machine       machin\n",
      "25       learning        learn\n",
      "26          cloud        cloud\n",
      "27     computing.   computing.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(word) for word in filtered_text]\n",
    "\n",
    "stemdf = pd.DataFrame({'original_word': filtered_text, 'stemmed_word': stemmed_words})\n",
    "print(stemdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sugan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Sugan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'Suganraj,', 'third', 'year', 'Computer', 'Science', 'Student', \"I'm\", 'passionate', 'artificial', 'intelligence', 'machine', 'learn', 'do', 'certification', 'AWS', 'cloud', 'practitioner', 'Microsost', 'Azure', 'Ai', '900', 'do', 'project', 'Machine', 'learn', 'cloud', 'computing.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in filtered_text]\n",
    "print(lemmatized_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
